{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part1 基本概览"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensor:表示数据,可以是单个数值或数组等\n",
    "- constant:常数\n",
    "- Variable：变量\n",
    "- op:表示对tensor的操作(operation)，产生1或多个tensor\n",
    "- graph：表示计算任务，含有多个op,op又称为图中节点\n",
    "- session:graph要在session中才能启动\n",
    "- 使用feed和fetch可以为任意的操作赋值或者从其中获取数据\n",
    "- 常用函数\n",
    "    - tf.constant([[3,3]])\n",
    "    - tf.Variable([1,2])\n",
    "    - tf.add(a,b) \n",
    "    - tf.subtract(a,b) \n",
    "    - tf.mutiply(a,b) \n",
    "    - tf.matmul(m1,m2) \n",
    "    - tf.assign(a,b) \n",
    "    - tf.equal(a,b) \n",
    "    - tf.cast(correct_pred,tf.float32) \n",
    "    - tf.argmax(y,axis=1)\n",
    "    - tf.placeholder(tf.float32)\n",
    "    - tf.reduce_mean(tf.square(y-y_data))\n",
    "    - tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "    - tf.nn.tanh(tf.matmul(x,W1)+b1) \n",
    "    - tf.nn.softmax(tf.matmul(x,W)+b) \n",
    "    - tf.nn.dropout(L1,ratio)    \n",
    "    - tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pred)\n",
    "    - tf.random_normal([1,10])# tf.random_normal 从服从正态分布的数据拿出数据，[1,10]表示拿10个元素，并把它变成1*10矩阵\n",
    "    - tf.truncated_normal([784,2000],stddev=0.1)#tf.truncated_normal从截断的正态分布取数据，如果大于2个标准差则舍弃\n",
    "    - tf.summary.FileWriter('logs/',sess.graph)# 记录图结构，用于在tensorboard展示\n",
    "    - tf.summary.scalar('mean',mean)# 用来显示标量信息\n",
    "    - tf.summary.histogram('histogram',var)# 用来显示直方图信息\n",
    "    - tf.summary.merge_all()# 将所有summary全部保存到磁盘，以便tensorboard显示。\n",
    "    - tf.reduce_max(var)# 一组数中最大的数\n",
    "    - tf.reduce_min(var)# 一组数中最小的数\n",
    "    - tf.stack([a,b],axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1 创建图，启动图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个常量矩阵op\n",
    "m1=tf.constant([[3,3]])\n",
    "# 创建一个常量矩阵op\n",
    "m2=tf.constant([[2],[3]])\n",
    "# 创建一个矩阵乘法op,将m1和m2传入\n",
    "product=tf.matmul(m1,m2)\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个会话，启动默认图，可以自动关闭\n",
    "with tf.Session() as sess:\n",
    "    sess.run(product)\n",
    "    print(sess.run(product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2 变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.Variable([1,2])\n",
    "a=tf.Variable([3,3])\n",
    "# 创建一个减法op\n",
    "sub=tf.subtract(x,a)\n",
    "# 创建一个加法op\n",
    "add=tf.add(sub,a)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(sub))\n",
    "    print(sess.run(add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个变量初始化为0\n",
    "state=tf.Variable(0,name='state')\n",
    "# 创建一个变量op，使state+1\n",
    "new_value=tf.add(state,1)\n",
    "# 赋值op\n",
    "update=tf.assign(state,new_value)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(5):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3 Fetch and Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fetch，可以输出多个op\n",
    "input1=tf.constant(3.0)\n",
    "input2=tf.constant(2.0)\n",
    "input3=tf.constant(5.0)\n",
    "\n",
    "add=tf.add(input2,input3)\n",
    "mul=tf.multiply(add,input1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result=sess.run([mul,add])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed，需要结合placeholder\n",
    "input1=tf.placeholder(tf.float32)\n",
    "input2=tf.placeholder(tf.float32)\n",
    "output=tf.multiply(input1,input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result=sess.run(output,feed_dict={input1:[12],input2:[2]})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-4 Tensorflow简单实例-拟合直线，其实也就是已知是直线，求斜率k和b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=np.random.rand(100)\n",
    "y_data=3*x_data+12\n",
    "\n",
    "b=tf.Variable(0.)\n",
    "k=tf.Variable(0.)\n",
    "y=k*x_data+b\n",
    "\n",
    "# 二次代价函数\n",
    "loss=tf.reduce_mean(tf.square(y-y_data))\n",
    "# 定义梯度下降法来求解最优解\n",
    "optimizer=tf.train.GradientDescentOptimizer(0.2)\n",
    "# 最小化代价函数\n",
    "train=optimizer.minimize(loss)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(201):\n",
    "        sess.run(train)\n",
    "        if step%20==0:\n",
    "            print(sess.run([k,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1 拟合曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=np.linspace(-0.5,0.5,200)[:,np.newaxis]\n",
    "# 均值为0，标准差为0.02\n",
    "noise=np.random.normal(0,0.02,x_data.shape)\n",
    "y_data=np.square(x_data)+noise\n",
    "\n",
    "x=tf.placeholder(tf.float32,[None,1])\n",
    "y=tf.placeholder(tf.float32,[None,1])\n",
    "\n",
    "# 中间层\n",
    "# 因为x是None*1矩阵，所以W1需要是1*多少的矩阵\n",
    "W1=tf.Variable(tf.random_normal([1,10]))# tf.random_normal 从服从正态分布的数据拿出数据，[1,10]表示拿10个元素，并把它变成1*10矩阵\n",
    "# b的值只能两种取值，一种是1*该层神经元个数大小矩阵，本题是1*10的矩阵[1,10],建议，可省略为[10];\n",
    "# 另一种是样本行数*1大小矩阵，本题是200*1的矩阵[200,1]，不建议\n",
    "b1=tf.Variable(tf.zeros([1,10]))\n",
    "L1=tf.nn.tanh(tf.matmul(x,W1)+b1)# 双曲正切作为激活函数\n",
    "\n",
    "# 输出层\n",
    "W2=tf.Variable(tf.random_normal([10,1]))# 上一层是10列，所以这一层是10行\n",
    "b2=tf.Variable(tf.zeros([1,1]))\n",
    "prediction=tf.nn.tanh(tf.matmul(L1,W2)+b2)\n",
    "\n",
    "loss=tf.reduce_mean(tf.square(y-prediction))\n",
    "train_step=tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(2000):\n",
    "        sess.run(train_step,feed_dict={x:x_data,y:y_data})\n",
    "        \n",
    "    prediction_value=sess.run(prediction,feed_dict={x:x_data})\n",
    "    plt.figure()\n",
    "    plt.scatter(x_data,y_data)\n",
    "    plt.plot(x_data,prediction_value,'r-',lw=6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2 MINST数据集分类简单版本-只含输入层和输出层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 获取的是IDX文件格式，是一种用来存储向量与多维度矩阵的文件格式。\n",
    "mnist=input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size=100\n",
    "n_batch=mnist.train.num_examples//batch_size# 整数除\n",
    "\n",
    "x=tf.placeholder(tf.float32,[None,784])#图片尺寸是28像素*28像素=784，一张图片压缩为一行向量，长度784\n",
    "y=tf.placeholder(tf.float32,[None,10])#label本来是1列，表示数字0-9，one-hot后是10列\n",
    "\n",
    "# 创建一个简单的神经网络，不含中间层\n",
    "W=tf.Variable(tf.zeros([784,10]))# 如果取tf.random_normal([784,10]),可能是局部最优解，效果不好\n",
    "b=tf.Variable(tf.zeros([1,10]))\n",
    "pred=tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "loss=tf.reduce_mean(tf.square(y-pred))\n",
    "train_step=tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "# 求准确率\n",
    "correct_pred=tf.equal(tf.argmax(y,axis=1),tf.argmax(pred,axis=1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_x,y:batch_y})\n",
    "        acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print('Iteration'+str(i)+',testing accuracy:'+str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1 交叉熵,重新定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size=100\n",
    "n_batch=mnist.train.num_examples// batch_size\n",
    "\n",
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "y=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W=tf.Variable(tf.zeros([784,10]))\n",
    "b=tf.Variable(tf.zeros([1,10])+0.1)\n",
    "pred=tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pred))\n",
    "train_step=tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "# 求准确率\n",
    "correct_pred=tf.equal(tf.argmax(y,axis=1),tf.argmax(pred,axis=1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_x,y:batch_y})\n",
    "        acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print('Iteration'+str(i)+',testing accuracy:'+str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-2 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size=100\n",
    "n_batch=mnist.train.num_examples// batch_size\n",
    "\n",
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "y=tf.placeholder(tf.float32,[None,10])\n",
    "ratio=tf.placeholder(tf.float32)\n",
    "\n",
    "# 创建含3个中间层的神经网络\n",
    "#tf.truncated_normal从截断的正态分布取数据，如果大于2个标准差则舍弃,此时比tf.zeros效果要好\n",
    "W1=tf.Variable(tf.truncated_normal([784,2000],stddev=0.1))\n",
    "b1=tf.Variable(tf.zeros([1,2000])+0.1)\n",
    "L1=tf.nn.tanh(tf.matmul(x,W1)+b1)\n",
    "L1_drop=tf.nn.dropout(L1,ratio)\n",
    "\n",
    "W2=tf.Variable(tf.truncated_normal([2000,2000],stddev=0.1))\n",
    "b2=tf.Variable(tf.zeros([1,2000])+0.1)\n",
    "L2=tf.nn.tanh(tf.matmul(L1_drop,W2)+b2)\n",
    "L2_drop=tf.nn.dropout(L2,ratio)\n",
    "\n",
    "W3=tf.Variable(tf.truncated_normal([2000,1000],stddev=0.1))\n",
    "b3=tf.Variable(tf.zeros([1,1000])+0.1)\n",
    "L3=tf.nn.tanh(tf.matmul(L2_drop,W3)+b3)\n",
    "L3_drop=tf.nn.dropout(L3,ratio)\n",
    "\n",
    "W4=tf.Variable(tf.truncated_normal([1000,10],stddev=0.1))\n",
    "b4=tf.Variable(tf.zeros([1,10])+0.1)\n",
    "pred=tf.nn.softmax(tf.matmul(L3_drop,W4)+b4)\n",
    "\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pred))\n",
    "train_step=tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "# 求准确率\n",
    "correct_pred=tf.equal(tf.argmax(y,axis=1),tf.argmax(pred,axis=1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_x,y:batch_y,ratio:0.7})\n",
    "        test_acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,ratio:1.0})\n",
    "        train_acc=sess.run(accuracy,feed_dict={x:mnist.train.images,y:mnist.train.labels,ratio:1.0})\n",
    "        print('Iteration'+str(i)+',testing accuracy:'+str(test_acc)+',training accuracy:'+str(train_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-3 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size=100\n",
    "n_batch=mnist.train.num_examples// batch_size\n",
    "\n",
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "y=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W=tf.Variable(tf.zeros([784,10]))\n",
    "b=tf.Variable(tf.zeros([1,10])+0.1)\n",
    "pred=tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pred))\n",
    "train_step=tf.train.AdamOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "# 求准确率\n",
    "correct_pred=tf.equal(tf.argmax(y,axis=1),tf.argmax(pred,axis=1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_x,y:batch_y})\n",
    "        acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print('Iteration'+str(i)+',testing accuracy:'+str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1 MNIST数据集分类改进-不断调节最优化算法步长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size=100\n",
    "n_batch=mnist.train.num_examples// batch_size\n",
    "\n",
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "y=tf.placeholder(tf.float32,[None,10])\n",
    "ratio=tf.placeholder(tf.float32)\n",
    "rate=tf.Variable(0.01,dtype=tf.float32)\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W1=tf.Variable(tf.truncated_normal([784,500],stddev=0.1))\n",
    "b1=tf.Variable(tf.zeros([1,500])+0.1)\n",
    "L1=tf.nn.tanh(tf.matmul(x,W1)+b1)\n",
    "L1_drop=tf.nn.dropout(L1,ratio)\n",
    "\n",
    "W2=tf.Variable(tf.truncated_normal([500,300],stddev=0.1))\n",
    "b2=tf.Variable(tf.zeros([1,300])+0.1)\n",
    "L2=tf.nn.tanh(tf.matmul(L1_drop,W2)+b2)\n",
    "L2_drop=tf.nn.dropout(L2,ratio)\n",
    "\n",
    "W3=tf.Variable(tf.truncated_normal([300,10],stddev=0.1))\n",
    "b3=tf.Variable(tf.zeros([1,10])+0.1)\n",
    "pred=tf.nn.softmax(tf.matmul(L2_drop,W3)+b3)\n",
    "\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pred))\n",
    "train_step=tf.train.AdamOptimizer(rate).minimize(loss)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "# 求准确率\n",
    "correct_pred=tf.equal(tf.argmax(y,axis=1),tf.argmax(pred,axis=1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(21):\n",
    "        sess.run(tf.assign(rate,0.01*(0.95**i)))\n",
    "        for batch in range(n_batch):\n",
    "            batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_x,y:batch_y,ratio:1})\n",
    "        test_acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,ratio:1.0})\n",
    "        learning_rate=sess.run(rate)\n",
    "        print('Iteration'+str(i)+',testing accuracy:'+str(test_acc)+',learning rate:'+str(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2 tensorboard简单网络结构可视化\n",
    "- Anaconda Prompt 命令：tensorboard --logdir=C:\\Users\\Administrator.SKY-20170617YWV\\1_tensorflow\\logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size=100\n",
    "n_batch=mnist.train.num_examples//batch_size\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    x=tf.placeholder(tf.float32,[None,784],name='x_input')\n",
    "    y=tf.placeholder(tf.float32,[None,10],name='y_input')\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "with tf.name_scope('layer'):\n",
    "    with tf.name_scope('weights'):\n",
    "        W=tf.Variable(tf.zeros([784,10]))\n",
    "    with tf.name_scope('biases'):\n",
    "        b=tf.Variable(tf.zeros([1,10]))\n",
    "    with tf.name_scope('xw_plus_b'):\n",
    "        L=tf.matmul(x,W)+b\n",
    "    with tf.name_scope('softmax'):\n",
    "        pred=tf.nn.softmax(L)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss=tf.reduce_mean(tf.square(y-pred))\n",
    "with tf.name_scope('train'):\n",
    "    train=tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.name_scope('calculate'):\n",
    "    with tf.name_scope('correct_pred'):\n",
    "        correct_pred=tf.equal(tf.argmax(y,axis=1),tf.argmax(pred,1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # ☆☆☆\n",
    "    writer=tf.summary.FileWriter('logs/',sess.graph)\n",
    "    for i in range(1):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys=mnist.train.next_batch(batch_size)\n",
    "            sess.run(train,feed_dict={x:batch_xs,y:batch_ys})\n",
    "        acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print('Iteration'+str(i)+',test accuracy:'+str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-3 tensorboard进阶网络结构可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist=input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size=100\n",
    "n_batch=mnist.train.num_examples//batch_size\n",
    "\n",
    "# 参数概要\n",
    "def variable_summary(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean=tf.reduce_mean(var)\n",
    "        # ☆☆☆\n",
    "        tf.summary.scalar('mean',mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev=tf.sqrt(tf.reduce_mean(tf.square(var-mean)))\n",
    "        tf.summary.scalar('stddev',stddev)\n",
    "        tf.summary.scalar('max',tf.reduce_max(var))\n",
    "        tf.summary.scalar('min',tf.reduce_min(var))\n",
    "        # ☆☆☆\n",
    "        tf.summary.histogram('histogram',var)\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    x=tf.placeholder(tf.float32,[None,784],name='x_input')\n",
    "    y=tf.placeholder(tf.float32,[None,10],name='y_input')\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "with tf.name_scope('layer'):\n",
    "    with tf.name_scope('weights'):\n",
    "        W=tf.Variable(tf.zeros([784,10]))\n",
    "        variable_summary(W)\n",
    "    with tf.name_scope('biases'):\n",
    "        b=tf.Variable(tf.zeros([1,10]))\n",
    "        variable_summary(b)\n",
    "    with tf.name_scope('xw_plus_b'):\n",
    "        L=tf.matmul(x,W)+b\n",
    "    with tf.name_scope('softmax'):\n",
    "        pred=tf.nn.softmax(L)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss=tf.reduce_mean(tf.square(y-pred))\n",
    "    tf.summary.scalar('loss',loss)\n",
    "with tf.name_scope('train'):\n",
    "    train=tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.name_scope('calculate'):\n",
    "    with tf.name_scope('correct_pred'):\n",
    "        correct_pred=tf.equal(tf.argmax(y,1),tf.argmax(pred,1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "        tf.summary.scalar('accuracy',accuracy)\n",
    "        \n",
    "# ☆☆☆\n",
    "merged=tf.summary.merge_all()\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # ☆☆☆\n",
    "    writer=tf.summary.FileWriter('logs/',sess.graph)\n",
    "    for i in range(51):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys=mnist.train.next_batch(batch_size)\n",
    "            # ☆☆☆\n",
    "            summary,_=sess.run([merged,train],feed_dict={x:batch_xs,y:batch_ys})\n",
    "        # ☆☆☆\n",
    "        writer.add_summary(summary,i)\n",
    "        acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print('Iteration'+str(i)+',test accuracy:'+str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-4 tensorboard运行可视化\n",
    "- 新建projector文件夹，文件夹中含有data和project文件夹，其中data文件夹有张png图片，图片有10000个手写数字。\n",
    "- 运行前需要清空project/project文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "# 载入数据集\n",
    "mnist=input_data.read_data_sets('MNIST_data/',one_hot=True)\n",
    "# 运行次数\n",
    "max_steps=1000\n",
    "# 图片数量\n",
    "image_num=3000\n",
    "# 文件路径\n",
    "dir='C:/Users/Administrator.SKY-20170617YWV/1_tensorflow/'\n",
    "\n",
    "# 定义会话\n",
    "sess=tf.Session()\n",
    "\n",
    "# 载入image_num张图片\n",
    "embedding=tf.Variable(tf.stack(mnist.test.images[:image_num]),trainable=True,name='embedding')\n",
    "\n",
    "# 参数概要\n",
    "def variable_summary(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean=tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean',mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev=tf.sqrt(tf.reduce_mean(tf.square(var-mean)))\n",
    "        tf.summary.scalar('stddev',stddev)\n",
    "        tf.summary.scalar('max',tf.reduce_max(var))\n",
    "        tf.summary.scalar('min',tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram',var)\n",
    "        \n",
    "# 命名空间\n",
    "with tf.name_scope('input'):\n",
    "    x=tf.placeholder(tf.float32,[None,784],name='x_input')\n",
    "    y=tf.placeholder(tf.float32,[None,10],name='y_input')\n",
    "    \n",
    "# 显示图片\n",
    "with tf.name_scope('input_reshape'):\n",
    "    # -1代表图片数量不确定，黑白图片维度为1\n",
    "    image_shaped_input=tf.reshape(x,[-1,28,28,1])\n",
    "    # 传入10张图片\n",
    "    tf.summary.image('input',image_shaped_input,10)\n",
    "    \n",
    "# 创建一个简单的神经网络\n",
    "with tf.name_scope('layer'):\n",
    "    with tf.name_scope('weights'):\n",
    "        W=tf.Variable(tf.zeros([784,10]),name='W')\n",
    "        variable_summary(W)\n",
    "    with tf.name_scope('biases'):\n",
    "        b=tf.Variable(tf.zeros([10]),name='b')\n",
    "        variable_summary(b)\n",
    "    with tf.name_scope('xw_plus_b'):\n",
    "        xw_plus_b=tf.matmul(x,W)+b\n",
    "    with tf.name_scope('softmax'):\n",
    "        prediction=tf.nn.softmax(xw_plus_b)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "    tf.summary.scalar('loss',loss)\n",
    "with tf.name_scope('train'):\n",
    "    train_step=tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        # 结果存放在一个布尔型列表中,argmax返回一维张量中最大值所在的位置\n",
    "        correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        # 求准确率\n",
    "        accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        tf.summary.scalar('accuracy',accuracy)\n",
    "        \n",
    "# 需要生成metadata.tsv,写入测试集图片前image_num张图片的标签（0-9）\n",
    "if tf.gfile.Exists(dir+'projector/projector/metadata.tsv'):\n",
    "    tf.gfile.DeleteRecursively(dir+'projector/projector/metadata.tsv')\n",
    "with open(dir+'projector/projector/metadata.tsv','w') as f:\n",
    "    labels=sess.run(tf.argmax(mnist.test.labels[:],1))\n",
    "    for i in range(image_num):\n",
    "        f.write(str(labels[i])+'\\n')\n",
    "        \n",
    "# 合并所有的指标\n",
    "merged=tf.summary.merge_all()\n",
    "\n",
    "# 固定配置写法\n",
    "projector_writer=tf.summary.FileWriter(dir+'projector/projector',sess.graph)\n",
    "saver=tf.train.Saver()# 用于保存模型\n",
    "config=projector.ProjectorConfig()\n",
    "embed=config.embeddings.add()\n",
    "embed.tensor_name=embedding.name\n",
    "embed.metadata_path=dir+'projector/projector/metadata.tsv'\n",
    "embed.sprite.image_path=dir+'projector/data/mnist_10k_sprite.png'\n",
    "embed.sprite.single_image_dim.extend([28,28])\n",
    "projector.visualize_embeddings(projector_writer,config)\n",
    "\n",
    "for i in range(max_steps):\n",
    "    batch_xs,batch_ys=mnist.train.next_batch(100)\n",
    "    \n",
    "    # 固定配置写法\n",
    "    run_options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "    run_metadata=tf.RunMetadata()\n",
    "    \n",
    "    # ☆☆☆\n",
    "    summary,_=sess.run([merged,train_step],feed_dict={x:batch_xs,y:batch_ys},options=run_options,run_metadata=run_metadata)\n",
    "    projector_writer.add_run_metadata(run_metadata,'step%03d' % i)\n",
    "    projector_writer.add_summary(summary,i)\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print('Iteration'+str(i)+',testing accuracy'+str(acc))\n",
    "\n",
    "saver.save(sess,dir+'projector/projector/a_model.ckpt',global_step=max_steps)\n",
    "projector_writer.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-1 CNN应用于MNIST数据集分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "\n",
    "batch_size=100\n",
    "n_batch=mnist.train.num_examples // batch_size\n",
    "\n",
    "# 初始化权值\n",
    "def weight_variable(shape):\n",
    "    initial=tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 初始化偏置\n",
    "def bias_variable(shape):\n",
    "    initial=tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 卷积层\n",
    "def conv2d(x,W):\n",
    "    # x是4维，[a,b,c,d],a是批次数量，b是高度，c是宽度，d是平面个数\n",
    "    # W滤波器窗口，[a,b,c,d],a是长度，b是宽度，c是输入平面数，d是输出平面数\n",
    "    # 步长strides=[a,b,c,d],默认a=d=1，b是x方向步长，c是y方向步长\n",
    "    # padding,选取'SAME'属性，则会补0\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "# 池化层\n",
    "def max_pool_2x2(x):\n",
    "    # 过滤器ksize=[a,b,c,d]，默认a=d=1，b是x方向窗口长度，c是y方向窗口长度\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "y=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "# -1表示批次数量，最后一个1表示channel，二维，彩色的是3。在这里将一个样本的原始数据1*784矩阵，变成二维图片，二维矩阵\n",
    "x_image=tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "# 初始化第一个卷积层的权值和偏置\n",
    "# 5x5采样窗口，黑白图片为1，32个卷积核从1个平面(黑白图片为1个平面彩色图片为3个平面)产生32个输出平面\n",
    "W1=weight_variable([5,5,1,32])\n",
    "b1=bias_variable([32])\n",
    "\n",
    "h_conv1=tf.nn.relu(conv2d(x_image,W1)+b1)\n",
    "h_pool1=max_pool_2x2(h_conv1)\n",
    "\n",
    "# 初始化第二个卷积层的权值和偏置\n",
    "# 5x5采样窗口，64个卷积核从32个平面(产生64个输出平面\n",
    "W2=weight_variable([5,5,32,64])\n",
    "b2=bias_variable([64])\n",
    "\n",
    "h_conv2=tf.nn.relu(conv2d(h_pool1,W2)+b2)\n",
    "h_pool2=max_pool_2x2(h_conv2)\n",
    "\n",
    "# 28*28的图片第一次卷积后还是28*28(补0)，第一次池化后变成14*14(窗口2*2，则除以2，本来就是为了较少数据量的)\n",
    "# 28*28的图片第二次卷积后还是14*14(补0)，池化后变成7*7(窗口2*2，则除以2，本来就是为了较少数据量的)\n",
    "# 最终得到64个7*7的平面\n",
    "\n",
    "# 初始化第一个全连接层的权值\n",
    "# 将64个7*7的平面变成7*7*64个输入神经元，输出层定义1024个神经元\n",
    "W_fc1=weight_variable([7*7*64,1024])\n",
    "b_fc1=bias_variable([1024])\n",
    "\n",
    "# 池化层2输出为[a,b,c,d]，a为批次数量，b=7,c=7,d=64,扁平化为1维\n",
    "h_pool2_flat=tf.reshape(h_pool2,[-1,7*7*64])\n",
    "h_fc1=tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n",
    "\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "h_fc1_drop=tf.nn.dropout(h_fc1,keep_prob)\n",
    "\n",
    "# 初始化第二个全连接层\n",
    "W_fc2=weight_variable([1024,10])\n",
    "b_fc2=bias_variable([10])\n",
    "\n",
    "# 计算输出\n",
    "pred=tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)\n",
    "\n",
    "# 交叉熵代价函数\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pred))\n",
    "# 使用AdamOptimizer优化\n",
    "train=tf.train.AdadeltaOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 求准确率\n",
    "correct_prediction=tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys=mnist.train.next_batch(batch_size)\n",
    "            sess.run(train,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.7})\n",
    "        acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        print('Iteration'+str(i)+\",test accuracy=\"+str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-2 CNN应用于MNIST数据集分类之tensorboard可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "\n",
    "batch_size=100\n",
    "n_batch=mnist.train.num_examples // batch_size\n",
    "\n",
    "def variable_smmaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean=tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean',mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev=tf.sqrt(tf.reduce_mean(tf.square(var-mean)))\n",
    "        tf.summary.scalar('stddev',stddev)\n",
    "        tf.summary.scalar('max',tf.reduce_max(var))\n",
    "        tf.summary.scalar('min',tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram',var)\n",
    "        \n",
    "def weight_variable(shape,name):\n",
    "    initial=tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial,name=name)\n",
    "\n",
    "def bias_variable(shape,name):\n",
    "    initial=tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial,name=name)\n",
    "\n",
    "\n",
    "# 卷积层，W是窗口，非权值\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "# 池化层\n",
    "# 过滤器ksize=[a,b,c,d]，默认a=d=1，b是x方向窗口长度，c是y方向窗口长度\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    x=tf.placeholder(tf.float32,[None,784],name='x-input')\n",
    "    y=tf.placeholder(tf.float32,[None,10],name='y-input')\n",
    "    with tf.name_scope('x_image'):\n",
    "        # -1表示不确定的数，最后一个1表示channel，二维，彩色的是3。在这里将一个样本的原始数据1*784矩阵，变成二维图片，二维矩阵\n",
    "        x_image=tf.reshape(x,[-1,28,28,1],name='x_image')\n",
    "    \n",
    "# 第一个卷积层和池化层\n",
    "with tf.name_scope('conv1'):\n",
    "    with tf.name_scope('w_conv1'):\n",
    "        # 5x5采样窗口，黑白图片为1，32个卷积核从1个平面(黑白图片为1个平面彩色图片为3个平面)产生32个输出平面，\n",
    "        w_conv1=weight_variable([5,5,1,32],name='w_conv1')\n",
    "    with tf.name_scope('b_conv1'):\n",
    "        b_conv1=bias_variable([32],name='b_conv1')\n",
    "        \n",
    "    with tf.name_scope('conv2d_1'):\n",
    "        conv2d_1=conv2d(x_image,w_conv1)+b_conv1\n",
    "    with tf.name_scope('relu'):\n",
    "        h_conv1=tf.nn.relu(conv2d_1)\n",
    "    with tf.name_scope('h_pool1'):\n",
    "        h_pool1=max_pool_2x2(h_conv1)\n",
    "\n",
    "# 第二个卷积层和池化层        \n",
    "with tf.name_scope('conv2'):\n",
    "    with tf.name_scope('w_conv2'):\n",
    "        # 64个卷积核从32个平面抽取特征，64个卷积核从每个个平面抽取出平面特征(激活，则会抽出，否则不抽出) \n",
    "        w_conv2=weight_variable([5,5,32,64],name='w_conv2')\n",
    "    with tf.name_scope('b_conv2'):\n",
    "        b_conv2=bias_variable([64],name='b_conv2')\n",
    "        \n",
    "    with tf.name_scope('conv2d_2'):\n",
    "        conv2d_2=conv2d(h_pool1,w_conv2)+b_conv2\n",
    "    with tf.name_scope('relu'):\n",
    "        h_conv2=tf.nn.relu(conv2d_2)\n",
    "    with tf.name_scope('h_pool2'):\n",
    "        h_pool2=max_pool_2x2(h_conv2)    \n",
    "        \n",
    "# 28*28的图片第一次卷积后还是28*28(补0)，第一次池化后变成14*14(窗口2*2，则除以2，本来就是为了较少数据量的)\n",
    "# 28*28的图片第二次卷积后还是14*14(补0)，池化后变成7*7(窗口2*2，则除以2，本来就是为了较少数据量的)\n",
    "# 最终得到64个7*7的平面\n",
    "        \n",
    "# 第一个全连接层,w为权值\n",
    "with tf.name_scope('fc1'):\n",
    "    with tf.name_scope('w_fc1'):\n",
    "        # 将64个7*7的平面变成7*7*64个输入神经元，输出层定义1024个神经元\n",
    "        w_fc1=weight_variable([7*7*64,1024],name='w_fc1')\n",
    "    with tf.name_scope('b_fc1'):\n",
    "        b_fc1=bias_variable([1024],name='b_fc1')\n",
    "        \n",
    "#     将池化层2输出扁平化为1维，[a,b,c,d]，a为批次，b=7,c=7,d=64\n",
    "    with tf.name_scope('h_pool2_flat'):\n",
    "        h_pool2_flat=tf.reshape(h_pool2,[-1,7*7*64])\n",
    "    with tf.name_scope('xw_plus_b1'):\n",
    "        xw_plus_b1=tf.matmul(h_pool2_flat,w_fc1)+b_fc1\n",
    "    with tf.name_scope('relu'):\n",
    "        h_fc1=tf.nn.relu(xw_plus_b1)\n",
    "        \n",
    "    with tf.name_scope('keep_prob'):\n",
    "        keep_prob=tf.placeholder(tf.float32,name='keep_prob')\n",
    "    with tf.name_scope('h_fc1_drop'):\n",
    "        h_fc1_drop=tf.nn.dropout(h_fc1,keep_prob,name='h_fc1_drop')\n",
    "        \n",
    "        \n",
    "# 第二个全连接层\n",
    "with tf.name_scope('fc2'):\n",
    "    with tf.name_scope('w_fc2'):\n",
    "        w_fc2=weight_variable([1024,10],name='w_fc2')\n",
    "    with tf.name_scope('b_fc2'):\n",
    "        b_fc2=bias_variable([10],name='b_fc2')\n",
    "    with tf.name_scope('xw_plus_b2'):\n",
    "        xw_plus_b2=tf.matmul(h_fc1_drop,w_fc2)+b_fc2\n",
    "    with tf.name_scope('softmax'):\n",
    "        prediction=tf.nn.softmax(xw_plus_b2)\n",
    "        \n",
    "# `交叉熵代价函数\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction),name='loss')\n",
    "    tf.summary.scalar('loss',loss)\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    train_step=tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "    \n",
    "with tf.name_scope('correct_prediction'):\n",
    "    correct_prediction=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "with tf.name_scope('accuracy'):\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    tf.summary.scalar('accuracy',accuracy)\n",
    "\n",
    "merged=tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_writer=tf.summary.FileWriter('logs/train',sess.graph)\n",
    "    test_writer=tf.summary.FileWriter('logs/test',sess.graph)\n",
    "    for i in range(4001):\n",
    "#         训练集\n",
    "        batch_xs,batch_ys=mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.5})\n",
    "        summary=sess.run(merged,feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.0})\n",
    "        train_writer.add_summary(summary,i)\n",
    "#         测试集\n",
    "        batch_xs,batch_ys=mnist.test.next_batch(batch_size)\n",
    "        summary=sess.run(merged,feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.0})\n",
    "        test_writer.add_summary(summary,i)\n",
    "        \n",
    "        if i%100==0 :\n",
    "            test_acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "            train_acc=sess.run(accuracy,feed_dict={x:mnist.train.images[:10000],y:mnist.train.labels[:10000],keep_prob:1.0})\n",
    "            print('Iteration'+str(i)+\",test accuracy=\"+str(test_acc)+',train accuracy='+str(train_acc))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7-1 LSTM应用于MNIST数据集分类简单版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "\n",
    "# 输入图片28*28\n",
    "n_inputs=28 #第i行，表示有28个输入神经元\n",
    "max_time=28 #一共28行，转化为序列问题,相当于一个样本28个神经元，一个神经元又有28个神经元\n",
    "lstm_size=100 #一个样本28个神经元，一个神经元又有28个神经元，第二个28个神经元的下一个隐藏层神经元个数设置为100\n",
    "n_classes=10\n",
    "batch_size=50 \n",
    "n_batch=mnist.train.num_examples // batch_size\n",
    "\n",
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "y=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "# 初始化全连接层\n",
    "weights=tf.Variable(tf.truncated_normal([lstm_size,n_classes],stddev=0.1))\n",
    "biases=tf.Variable(tf.constant(0.1,shape=[n_classes]))\n",
    "\n",
    "# 定义RNN网络\n",
    "def RNN(X,weights,biases):\n",
    "    # 还原成适合LSTM的输入形势\n",
    "    inputs=tf.reshape(X,[-1,max_time,n_inputs])# -1是batch_size,max_time是一张图片像素矩阵行数或者是一句话分词后的词语个数，n_inputs是embedding_size,图片对应像素矩阵每一行的列数/一个文本对应一个词语对应的词向量长度\n",
    "    # 定义LSTM基本单元\n",
    "    lstm_cell=tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    # final_state[0]是cell state输出，final_state[1]是hidden state输出，hidden_state后面即是最终输出结果\n",
    "    outputs,final_state=tf.nn.dynamic_rnn(lstm_cell,inputs,dtype=tf.float32)\n",
    "    results=tf.nn.softmax(tf.matmul(final_state[1],weights)+biases)\n",
    "    return results\n",
    "    \n",
    "# 预测\n",
    "pred=RNN(x,weights,biases)\n",
    "\n",
    "# 交叉熵代价函数\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pred))\n",
    "# 使用AdamOptimizer优化\n",
    "train=tf.train.AdadeltaOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 求准确率\n",
    "correct_prediction=tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(40):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys=mnist.train.next_batch(batch_size)\n",
    "            sess.run(train,feed_dict={x:batch_xs,y:batch_ys})\n",
    "        acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print('Iteration'+str(i)+\",test accuracy=\"+str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8-1 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "#每个批次100张照片\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#创建一个简单的神经网络，输入层784个神经元，输出层10个神经元\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "#二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维张量中最大的值所在的位置\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "# ☆☆☆\n",
    "saver=tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(11):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys =  mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "        \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n",
    "    # ☆☆☆\n",
    "    saver.save(sess,'net/my_net.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8-2 模型恢复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "#每个批次100张照片\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#创建一个简单的神经网络，输入层784个神经元，输出层10个神经元\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "#二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维张量中最大的值所在的位置\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "# ☆☆☆\n",
    "saver=tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels}))\n",
    "    # ☆☆☆\n",
    "    saver.restore(sess,'net/my_net.ckpt')\n",
    "    print(sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8-3 下载google图像识别网络inception-v3并查看结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import requests\n",
    "\n",
    "# 下载链接\n",
    "inception_pretrain_model_url='http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "\n",
    "# 压缩包存放地址\n",
    "inception_pretrain_model_dir='inception_model'\n",
    "if not os.path.exists(inception_pretrain_model_dir):\n",
    "    os.makedirs(inception_pretrain_model_dir)\n",
    "    \n",
    "# 获取文件名和文件路径\n",
    "filename=inception_pretrain_model_url.split('/')[-1]\n",
    "filepath=os.path.join(inception_pretrain_model_dir,filename)\n",
    "\n",
    "# 下载压缩包\n",
    "if not os.path.exists(filepath):\n",
    "    print('download: ',filename)\n",
    "    r=requests.get(inception_pretrain_model_url,stream=True)\n",
    "    with open(filepath,'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "print('finish: ',filename)\n",
    "\n",
    "# 解压\n",
    "tarfile.open(filepath,'r:gz').extractall(inception_pretrain_model_dir)\n",
    "\n",
    "# 模型结构存放文件\n",
    "log_dir='inception_log'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    \n",
    "# 下载好的模型路径\n",
    "inception_graph_def_file=os.path.join(inception_pretrain_model_dir,'classify_image_graph_def.pb')\n",
    "with tf.Session() as sess:\n",
    "    with tf.gfile.FastGFile(inception_graph_def_file,'rb') as f:\n",
    "        graph_def=tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def,name=\"\")\n",
    "    writer=tf.summary.FileWriter(log_dir,sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8-4 使用inception-v3做各种图像的识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class NodeLookup(object):\n",
    "    def __init__(self):\n",
    "        label_lookup_path='C:/Users/Administrator.SKY-20170617YWV/1_tensorflow/inception_model/imagenet_2012_challenge_label_map_proto.pbtxt'\n",
    "        uid_lookup_path='C:/Users/Administrator.SKY-20170617YWV/1_tensorflow/inception_model/imagenet_synset_to_human_label_map.txt'\n",
    "        self.node_lookup=self.load(label_lookup_path,uid_lookup_path)\n",
    "        \n",
    "    def load(self,label_lookup_path,uid_lookup_path):\n",
    "        uid_to_desc_lines=tf.gfile.GFile(uid_lookup_path).readlines()\n",
    "        uid_to_desc={}\n",
    "        for line in uid_to_desc_lines:\n",
    "            line=line.strip('\\n')\n",
    "            parsed_items=line.split('\\t')\n",
    "            uid=parsed_items[0]\n",
    "            desc=parsed_items[1]\n",
    "            uid_to_desc[uid]=desc\n",
    "        proto_to_uid=tf.gfile.GFile(label_lookup_path).readlines()\n",
    "        node_id_to_uid={}\n",
    "        for line in proto_to_uid:\n",
    "            if line.startswith('  target_class:'):\n",
    "                target_class=int(line.split(': ')[1])\n",
    "            if line.startswith('  target_class_string:'):\n",
    "                target_uid=line.split(': ')[1]\n",
    "                node_id_to_uid[target_class]=target_uid[1:-2]\n",
    "                \n",
    "        node_id_to_name={}\n",
    "        for key,val in node_id_to_uid.items():\n",
    "            name=uid_to_desc[val]\n",
    "            node_id_to_name[key]=name\n",
    "        return node_id_to_name\n",
    "    \n",
    "    def id_to_string(self,node_id):\n",
    "        if node_id not in self.node_lookup:\n",
    "            return ''\n",
    "        return self.node_lookup[node_id]\n",
    "    \n",
    "with tf.gfile.FastGFile('inception_model/classify_image_graph_def.pb','rb') as f:\n",
    "    graph_def=tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def,name='')\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    softmax_tensor=sess.graph.get_tensor_by_name('softmax:0')\n",
    "    for root,dirs,files in os.walk('images/'):\n",
    "        for file in files:\n",
    "            image_data=tf.gfile.FastGFile(os.path.join(root,file),'rb').read()\n",
    "            predictions=sess.run(softmax_tensor,{'DecodeJpeg/contents:0':image_data})\n",
    "            predictions=np.squeeze(predictions)\n",
    "            \n",
    "            image_path=os.path.join(root,file)\n",
    "            print(image_path)\n",
    "            img=Image.open(image_path)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            top_k=predictions.argsort()[-5:][::-1]\n",
    "            node_lookup=NodeLookup()\n",
    "            for node_id in top_k:\n",
    "                desc=node_lookup.id_to_string(node_id)\n",
    "                score=predictions[node_id]\n",
    "                print('%s (score=%.5f)' % (desc,score))\n",
    "\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
